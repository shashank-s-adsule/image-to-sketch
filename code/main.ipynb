{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder=\"input/*\"\n",
    "input_folder1=\"input1/*\"\n",
    "output_folder=os.getcwd()+\"\\\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorQuantization(img,k):\n",
    "    data=np.float32(img).reshape((-1,3))\n",
    "    \n",
    "    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "    \n",
    "    ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    result = center[label.flatten()]\n",
    "    result = result.reshape(img.shape)\n",
    "    return result\n",
    "\n",
    "def imagetosketch(idx,path,color_quantity):\n",
    "    img=cv2.imread(path)\n",
    "    grayimg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    edgeimg=cv2.adaptiveThreshold(grayimg,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,17,9)\n",
    "    img_c=colorQuantization(img,color_quantity)  #for refernce we have taken 8 for High quality image\n",
    "    colorimg=cv2.bilateralFilter(img_c,9,250,250)\n",
    "    sketch=cv2.bitwise_and(colorimg,colorimg,mask=edgeimg)\n",
    "    cv2.imwrite((output_folder+\"\\\\pic{num}.jpg\".format(num=idx)),sketch)\n",
    "    return True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pic1 0 True\n",
      "pic2 1002 True\n",
      "pic3 1005 True\n",
      "pic4 1008 True\n",
      "pic5 1011 True\n",
      "pic6 1014 True\n",
      "pic7 1017 True\n",
      "pic8 102 True\n",
      "pic9 1020 True\n",
      "pic10 1023 True\n",
      "pic11 1026 True\n",
      "pic12 1029 True\n",
      "pic13 1032 True\n",
      "pic14 1035 True\n",
      "pic15 1038 True\n",
      "pic16 1041 True\n",
      "pic17 1044 True\n",
      "pic18 1047 True\n",
      "pic19 105 True\n",
      "pic20 1050 True\n",
      "pic21 1053 True\n",
      "pic22 1056 True\n",
      "pic23 1059 True\n",
      "pic24 1062 True\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "for path in glob2.glob(input_folder1):\n",
    "    base=os.path.splitext(os.path.basename(path))[0]\n",
    "    print(\"pic{s}\".format(s=idx),base,imagetosketch(idx,path,128))\n",
    "    # imagetosketch(idx,path,8)\n",
    "    # test(path,idx)\n",
    "    idx+=1\n",
    "    \n",
    "    if(idx==25): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
